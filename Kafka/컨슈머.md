# 컨슈머

프로듀서 전송한 데이터는 카프카 브로커에 적재되고 컨슈머는 적재된 데이털르 사용하기 위해 브로커로 부터 데이터를 가져와서 처리를 하게 된다.

## 컨슈머 중요 개념

토픽의 파티션으로부터 데이터를 가져가기 위해 컨슈머를 운영하는 방법은 크게 2가지가 있다.

![스크린샷 2023-11-11 오후 9 09 28](https://github.com/kibongcoders/Study/assets/54662349/d74dd8ff-0d5f-45b0-8d5f-8c57932a33ff)


첫 번째 1개 이상의 컨슈머로 이루어진 컨슈머 그룹을 운영하는 것
두 번째는 토픽의 특정 파티션만 구독하는 컨슈머를 운영하는 것

### 컨슈머 그룹으로 운영하는 방법

컨슈머를 다른 컨슈머 그룹으로부터 격리된 환경에서 안정하게 운영할 수 있도록 도와주는 독특한 방식이다.

![스크린샷 2023-11-11 오후 9 09 38](https://github.com/kibongcoders/Study/assets/54662349/c682907f-a17f-44bc-9252-7ff7b897fdf9)

컨슈머 그룹의 컨슈머 개수는 가져가고자 하는 토픽의 파티션 개수보다 같거나 작아야한다 -> 놀고 있는 컨슈머가 생성될 수 있음

![스크린샷 2023-11-11 오후 9 13 35](https://github.com/kibongcoders/Study/assets/54662349/fc7cf07e-8d38-4c3d-ae24-62d82a23ace5)

엘라스틱서치에 저장에 문제가 생겨도 하둡에 저장되는 것에는 영향이 미치지 않도록 할 수 있다.

어디에 적재되고, 어떻게 처리되는지를 파악하고 컨슈머 그룹을 따로 나눌 수 있는 것은 최대한 나누는 것이 좋다.

#### 컨슈머 그룹의 장애가 발생되면 어떻게 될까?

해당 컨슈머에 장애가 발생하게 되면 장애가 할당된 파티션이 발생되지 않은 컨슈머로 소유권이 넘어가게 된다.

이것을 리밸런싱이라고 부른다

## Commit

#### 컨슈머는 어떻게 데이터를 어디까지 가져갔는지 알 수 있을까?

컨슈머는 commit을 통해 데이터를 어디까지 가져갔는지 기록한다.

![스크린샷 2023-11-15 오후 10 44 12](https://github.com/kibongcoders/Study/assets/54662349/5ba9898f-4f8e-4e12-b6bb-647fd7553f63)

어떤 컨슈머 그룹이 무엇을 가져갔는지 카프카 브로커 내부에서 사용되는 \_\_consumer_offsets
내부 토픽에 기록된다. 
만약 오프셋 커밋이 기록이 되지 못했다면 데이터 중복이 발생할 수 있다.

따라서 오프셋 커밋을 정상적으로 처리했는지 검증해야만 한다.

컨슈머 어플리케이션에서 명시적, 비명시적으로 수행 할 수 있는데

enable.auto.commit = true

- 비명시적 : 기본 옵션으로 poll() 메서드가 수행될 때 일정 간격마다 오프셋을 커밋
  auto.commit.interval.ms에 설정된 값으로 이 시간이 지났을 때 그 시점까지 읽은 레코드의 오프셋을 커밋한다.
  
  비명시적 오프셋 커밋은 편리하지만 리벨런싱 또는 컨슈머 강제종료 발생 시 데이터 중복 또는 유실이 발생될 수 있는 가능성이 있다.
  
- 명시적 : poll() 메서드 호출 이후 commitSync() 메서드를 호출하면 된다.
  poll() 메서드를 통해 반환된 레코드의 가장 마지막 오프셋을 기준으로  커밋을 수행한다.

내부에서 Fetcher 인스턴스가 생성 -> poll() 메서드를 호출

## 컨슈머 주요 옵션

### 필수 옵션

- bootstrap.servers : 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름:포트를 1개 이상 작성
- key.deserializer : 레코드의 메시지 키를 역직렬화하는 클래스 지정
- value.deserializer : 레코드의 메시지 값을 역직렬화하는 클래스를 지정

### 선택 옵션

- group.id : 컨슈머 그룹 아이디를 지정. subscribe() 메서드로 토픽을 구독하여 사용할 때는 이 옵션을 필수로 넣어야함
- auto.offset.reset : 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머 오프셋이 없는 경우 어느 오프셋부터 읽을지 선택하는 옵션
  이미 있다면 이 옵션은 무시
  latest, earliest, none 중에 하나로 설정 가능, latest - 가장 최근에 넣은 오프셋부터 읽기 시작, earliest - 가장 오래전에 넣은 것 부터 시작, none - 컨슈머 그룹이 커밋한 기록이 있는지 확인 후 없으면 오류 있으면 기록 이후부터 오프셋 읽기
  기본값은 latest
- enable.auto.commit : 자동 커밋, 수동 커밋 여부 선택 - 기본값 true
- auto.commit.interval.ms : 자동 커밋 일경우 오프셋간 커밋 간격
- max.poll.records : poll() 메서드를 통해 반환되는 레코드 개수 지정 - 기본값 500
- session.timeout.ms : 컨슈머와 브로커 연결 끊기는 최대 시간 이 시간 내에 하트비트를 전송 않하면 장애 발생으로 가정하고 리밸런싱 - 기본값 10000이다.
- hearbeat.interval.ms : 하트비트를 전송하는 시간 간격 - 기본값은 3000
- max.poll.interval.ms : poll() 메서드를 호출하는 간격의 최대 시간이다. 응답시간이 너무 오래 걸리는 경우 비정상으로 판단하고 리밸런싱 시작 - 기본값 300000(5분)
- isolation.level : 트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 경우 사용
  read_committed, read_uncommitted으로 설정 - 기본값 read_uncommitted
  - read_committed : 커밋이 완료된 레코드만 읽는다.
  - read_uncommitted : 커밋 여부와 관계없이 파티션에 있는 모든 레코드를 읽는다.

## 리밸런스 리스너를 가진 컨슈머

컨슈머 그룹에서 컨슈머가 추가 또는 제거되면 파티션을 재할당한다.(리밸런스)

컨슈머가 데이터를 처리하기 전에 리밸런스가 발생하면 데이터를 중복 처리할 수 있다.
(일부 처리하였으나 commit 하지 않음)

리밸런스 발생시 처리한 데이터를 기준으로 커밋을 시도해야한다.
리밸런스 발생을 감지하기 위해 카프카 라이브러리는 ConsumerRebalanceListener 인터페이스를 지원

ConsumerRebalanceListener는 onPartitionAssigned() 메서드와 onPartitionRevoked() 메서드로 이루어져 있다.

onPartitionAssigned() 메서드는 리밸런스가 끝난 뒤에 파티션이 할당 완료되면 호출되는 메서드
onPartitionRevoked() 메서드는 리밸런스가 시작되기 직전에 호출되는 메서드

마지막으로 처리한 레코드를 기준으로 커밋을 하기 위해서는 리밸런스가 시작하기 직전에 커밋을 하면 되므로 onPartitionRevoked() 매서드에 커밋을 구현하여 처리 가능

## 파티션 할당 컨슈머

컨슈머를 운영할 때 subscribe() 메서드를 사용하지 않아도 직접 파티션을 컨슈머에 명시적으로 할당하여 운영할 수도 있다.

컨슈머가 어떤 토픽, 파티션을 할당할지 명시적으로 선언할 때는 assign() 메서드를 사용하면 된다.

## 컨슈머에 할당된 파티션 확인 방법

컨슈머에 할당된 토픽과 파티션에 대한 정보는 assignment() 메서드로 확인 가능
Set\<TopicPartition\> 인스턴스 반환 (TopicPartition 클래스는 토픽 이름과 파티션 번호가 포함된 객체)

## 컨슈머의 안전한 종료

컨슈머 어플리케이션은 안전하게 종료되어야 한다.
정상적으로 종료되지 않은 컨슈머는 세션 타임아웃이 발생할때까지 컨슈머 그룹에 남게 된다.

실제로 종료 되었지만 동작하지 않는 컨슈머가 존재하면 컨슈머 랙에 늘어나게 되고 컨슈머 랙이 늘어나면 데이터 처리 지연이 발생하게 된다.

컨슈머를 안전하게 종료하기 위해 KafkaConsumer 클래스는 wakeup() 메서드를 지원하여 안전하게  종료 가능

종료된후 poll() 메서드 호출 시 WakeupException 예외가 발생

마지막에는 close() 메서드를 호출하여 카프카 클러스터에 컨슈머가 안전하게 종료되었음을 명시적으로 알려주면 종료가 완료 되었다고 볼 수 있다.

wakeup() 메서드는 셧다운 훅을 실행 시 넣어 주는 것이 좋다.

멀티 스레드 컨슈머

카프카는 처리량을 늘리기 위해 파티션과 컨슈머를 늘려서 운영할 수 있다.
여러 개로 운영하는 경우 데이터를 병렬처리하기 위해 파티션 개수와 컨슈머 개수를 동일하게 맞추는 것이 가장 좋은 방법이다.

파티션 개수가 n개라면 동일 컨슈머 그룹으로 묶인 컨슈머 스레드를 최대 n개 운영할 수 있다.
그러므로 n개의 스레드를 가진 1개의 프로세스를 운영하거나 1개의 스레드를 가진 프로세스를 n개 운영하는 방법도 있다.

멀티 스레드로 컨슈머를 안전하게 운영하기 위해선
먼저 프로스세스 내부에 여러개 생성되어 실행되기 때문에 컨슈머 스레드에서 예외적 상황이 발생할 경우 프로세스 자체가 종료 될 수 있고 다른 컨슈머 스레드에까지 영향을 미칠수 있다.
그렇기 때문에 스레드간 영향이 미치지 않도록 스레드 세이프 로직, 변수를 적용해야한다.

고려할 점이 많지만 안정적으로 개발한다면 매우 효율적으로 컨슈머를 운영할 수 있다.

컨슈머를 멀티 스레드로 활용하는 방식은 크게 2가지로 나뉜다.

1. 컨슈머는 1개 데이터 처리를 담당하는 워커 스레드 여러개 - 카프카 컨슈머 멀티 워커 스레드 전략
   멀티 스레드를 생성하는 ExecutorService 자바 라이브러리를 사용하면 레코드를 병렬처리하는 스레드를 효율적으로 생성하고 관리할  수 있다.
   Excutors를 상용하여 스레드 개수를 제어하는 스레드 풀을 생성할 수 있는데, 데이터 처리 환경에 맞는 스레드 풀을 사용하면 된다.
   이 방법의 주의 사항이 있는데,
   데이터 처리가 끝나지 않았음에도 커밋을 하기 때문에 리밸런싱, 컨슈머 장애 시 데이터 유실이 발생 가능
   처리 시간이 각자 다르기에 나중에게 먼저 끝날 경우 역전 현상이 발생할 수 있다.
2. 컨슈머가 여러개 - 카프카 컨슈머 멀티 스레드 전략
   하나의 파티션은 동일 컨슈머 중 1개까지 할당 되고 하나의 컨슈머는 여러 파티션에 할당될 수 있다.
   이런 특징을 잘살리는 방법은  1개의 어플리케이션에 구독하고자하는 토픽의 파티션 개수만큼 컨슈머 스레드 개수를 늘려서 운영하는 것
   컨슈머 스레드를 늘리면 각 스레드에 각 파티션이 할당 되어 병렬처리할 수 있다.

## 컨슈머 랙

토픽의 최신 오프셋과 컨슈머 오프셋 간의 차이
프로듀서는 계속해서 새로운 데이터를 파티션에 저장 -> 컨슈머는 자신이 처리할 수 있는 만큼 데이터를 가져간다.
컨슈머 랙은 컨슈머가 정상 동작하는지 여부를 확일 할 수 있기 때문에 컨슈머 어플리케이션을 운영한다면 필수적으로 모니터링으로 하는 지표이다.

컨슈머 랙이 발생하는 경우 파티션의 개수와 컨슈머의 개수를 늘려서 병렬 처리량을 늘리는 방법으로 처리한다.
물론, 컨슈머의 장애로 인해 컨슈머 랙이 증가할 수 도 있는데 데이터 양이 동일한데 컨슈머 랙이 늘어났다면 컨슈머에 이슈가 발생하였음을 유추할 수 있다.

컨슈머 랙을 확인하는 방법은 3가지가 있다.

1. 카프카 명령어 사용
   테스트용 카프카에서 주로 사용
2. 카프카 어플리케이션에서 metrics() 메서드를 사용하는 방법
   문제점
   정상 동작 할 때만 가능
   모든 컨슈머 어플리케이션에 컨슈머 랙 모니터링 코드를 중복 작성
   카프카 랙을 모니터링하는 코드를 추가할 수 없는 서드 파티 어플리케이션의 모니터링 불가
3. 외부 모니터링 툴을 사용하는 방법
   최선의 방법으로 데이터 독, 컨플루언트 컨트롤 센터와 같은 카프카 클러스터 종합 모니터링 툴을 사용하면 카프카 운영에 필요한 다영한 지표를 모니터링 가능
   컨슈머 랙 모니터링 만을 위해 Burrow가 있다.

### 카프카 버로우

REST API를 통해 컨슈머 그룹별 컨슈머 랙을 조회 가능
- /burrow/admin : 헬스체크
- /v3/kafka : 연동 중인 카프카 클러스터 리스트
- /v3/kafka/(클러스터 이름) : 클러스터 정보 조회
- /v3/kafka/(클러스터 이름) : 클러스터에 존재하는 컨슈머 그룹 리스트 
