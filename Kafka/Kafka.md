Scalar 언어로 된 오픈 소스 메시지 브로커 프로젝트이고 이벤트 드리븐 아키텍처와 스트림 데이터 파이프라인이다.

## 카프카 발생 배경

개발에 시간이 지날수록 아키텍처와 어플리케이션의 개수가 많아짐 -> [[MSA]]
소스 어플리케이션과 타깃 어플리케이션을 연결하는 파이프라인 개수가 많아지고 타깃 어플리케이션의 영향이 소스 어플리케이션에 미침

다양한 메시징 플랫폼과 ETL(Extract Transfom Load)툴을 적용하여 아키텍처를 변경하려고 하였지만 복잡도가 상승

링크드인의 데이터팀은 신규 시스템을 만들게 되는데 이것이 아파치 카프카이다.

카프카는 각각의 어플리케이션끼리 연결하는 것이 아닌 한 곳에 모아 처리할 수 있도록 중앙집중화하였고 이를 통해 대용량 데이터를 수집하고 사용자들이 실시간 스트림으로 소비할 수 있도록 변경되었다.

카프카는 [[데이터 레이크 아키텍처]] 중 카파 아키텍처로 이루어져 있다.

## 카프카가 데이터 파이프라인으로 적합한 이유

- 높은 처리량 : 카프카는 보내고 받을 때 데이터를 묶어서 보내기 때문에 네트워크 통신 횟수를 최소한으로 줄여 동일 시간에 많은 데이터를 전송할 수 있다. (실시간 로그데이터를 처리하는데 적합) 
    또한 동일 목적의 데이터를 여러 파티션에 분배하고 데이터를 병렬 처리할 수 있다. -> 파티션 개   수만큼 컨슈머 개수를 늘려서 동일 시간 데이터 처리량을 늘린다.
    
- 확장성 : 데이터 파이프라인에서 데이터를 모을 때 데이터가 얼마나 들어올지 예측하기 어려움 -> 카프카는 가변적인 환경에서 안정적으로 확장이 가능 
    데이터가 적을 때에는 최소한 개수로 운영하다가 데이터가 많아지면 브로커의 개수를 늘린다. (Scale-Out)
    다시 데이터가 적어지면 브로커 개수를 줄인다.(scale-in) 이 동작을 무중단으로 가능하다.
    
- 영속성 : 카프카는 전송 받은 데이터를 파일 시스템에 저장한다.
    카프카는 페이지 캐시 메모리 영역을 메모리에 따로 생성하고 사용하여 한번 읽은 내용은 메모리에 저장시켰다가 다시 사용하는 방식 -> 안전하게 처리 가능
    
- 고가용성 : 카프카는 3개 이상의 서버들로 운영되고 전송받은 데이터를 1대에 저장하는 것이 아닌 또 다른 브로커들에도 저장해 고가용성을 보장한다.

## 브로커, 클러스터, 주키퍼

### 브로커

카프카 클라이언트와 데이터를 주고받기 위해 사용되는 주체
데이터를 분산 저장 -> 장애 발생 시 안전하게 사용할 수 있도록 도와주는 어플리케이션
하나의 서버에는 한개의 카프카 브로커 프로세스가 실행된다.

### 클러스터

브로커의 묶음
1개도 가능하지만 안전을 위해 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영한다.

### 데이터 저장, 전송

카프카는 프로듀서 -> 브로커 -> 컨슈머 크게 이렇게 데이터를 저장, 전송한다.

카프카는 메모리나 따로 DB에 저장하지 않으며 따로 캐시메모리를 구현해서 사용하지 않고 파일 시스템에 저장하기 때문에 속도 문제가 발생하지 않을까 싶지만 [[페이지 캐시]]를 사용하여 디스크의 입출력 속도를 높여서 이 문제를 해결했다.

### 데이터 복제,싱크

데이터 복제는 카프카를 장애 허용 시스템으로 동작하도록 하는 원동력
장애 시 데이터를 유실하지 않고 안전하게 사용 가능

카프카의 데이터 복제는 파티션 단위로 이루어진다.
토픽 생성 시 파티션의 복제 개수도 같이 설정된다. (최소 1, 최대 브로커 개수)

복제된 파티션은 리더 파티션과 팔로우 파티션으로 구성된다.
- 리더 파티션 : 프로듀서 또는 컨슈머와 직접 통신
- 팔로워 파티션 : 복제된 데이터를 가지고 있는 파티션

저장 용량은 늘어나지만 2개 이상의 복제 개수를 정하는 것이 중요! -> 안정성

리더 파티션에 장애가 발생했을 경우 팔로워 파티션 중 하나의 파티션에서 그 지위를 넘겨 받고 프로듀서와 컨슈머와 데이터를 주고받도록 동작할 수 있다.

파티션의 개수는 유연하게 조절이 가능한데 
- 속도가 중요한 경우 : 복제 개수를 1, 2
- 안정성이 중요한 경우 : 복제 개수를 3개 이상

### 컨트롤러

클러스터의 다수 브로커 중 한 대가 컨트롤러 역활을 한다.
다른 브로커의 상태 관리하여 문제가 있는 브로커의 경우 클러스터에서 브로커를 제외하고 해당 브로커의 리더 파티션을 재분배한다.

지속적으로 데이터를 처리해야하기 때문에 클러스터에서 제외하는 것이 중요하다.
컨트롤러 브로커가 문제가 생긴 경우 다른 브로커가 그 역활을 대신한다.

### 데이터 삭제

카프카는 컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않는다.
또한 프로듀서와 컨슈머가 데이터 삭제 요청을 할 수 없고 오직 브로커만이 데이터 삭제를 요청할 수 있다.

데이터 삭제는 파일 단위로 이루어지고 이 단위를 [[로그 세그먼트]]라고 부른다.
세그먼트는 데이터가 쌓이는 동안 파일 시스템으로 열리고 브로커에 log.segement.bytes 또는 log.segment.ms 옵션에 설정 값이 넘겨지게 되면 세그먼트 파일이 닫힌다.

세그먼트 파일이 닫히게 되는 기본값은 1GB이다.
단힌 세그먼트 파일 log.retention.bytes, log.retention.ms 옵션의 설정값을 넘기면삭제 되고
세그먼트 파일을 체크하는 간격은 log.retention.check.interval.ms에 따른다.

### 컨슈머 오프셋 저장

컨슈머가 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋한다.
커밋한 오프셋은 __consumer_offsets 토픽에 저장한다.
여기에 저장된 오프셋을 기준으로 컨슈머 그룹은 다음 레코드를 가져가서 처리한다.

### 코디네이터

클러스터의 브로커 중 한 대는 코디네이터 역활을 수행한다.
코디네이터는 컨슈머 그룹의 상태 확인 후 파티션을 컨슈머와 매칭되도록 분배하는 역활

컨슈머가 컨슈머 그룹에서 빠져 매칭이 되지 않은 파티션은 컨슈머로 할당 -> 데이터가 처리되도록 도와준다 -> 리밸런스라고 부른다.

### 주키퍼

주키퍼는 카프카의 메타데이터를 관리하는 데에 사용
카프카 클러스터로 묶인 브로커들은 동일한 경로의 주키퍼 경로로 선언해야 같은 브로커 묶음이 된다.
만약 클러스터를 여러개 로 운영한다면 한개의 주키퍼에 다수의 카프카 클러스터를 연결해서 사용 가능

![[스크린샷 2023-11-10 오후 11.10.04.png]]

## 토픽, 파티션

### 토픽

데이터를 구분하기 위해 사용하는 단위. 토픽은 1개 이상의 파티션을 소유
이 파티션에는 프로듀서가 보낸 데이터들이 들어가 저장되고 이를 레코드라고 부른다.

![[스크린샷 2023-11-10 오후 11.11.41.png]]

파티션은 카프카의 병렬처리의 핵심이고 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭된다.

<span style="color:#f1c40f">레코드를 병렬 처리하는 가장 좋은 방법은 컨슈머의 개수를 늘려 스케일 아웃 하는 것이다.</span>
컨슈머 개수를 늘림과 동시에 파티션 개수도 늘리면 처리량이 증가하는 효과를 볼 수 있다.

![[스크린샷 2023-11-10 오후 11.15.14.png]]

파티션은 큐와 비슷한 구조(FIFO)이다. 먼저 들어간 레코드를 컨슈머가 먼저 가져가게 된다.

#### 토픽 이름 제약 조건

- 빈 문자열 X
- 마침표 하나 또는 둘로 생성 X
- 249자 미만
- 영어 대소문자, 0~9, . _ - 조합으로 생성 가능
- \_\_consumer _offsets, \_\_transaction_state 의 이름으로는 생성 불가능 -> 내부 생성 로직
- 토픽의 이름에 마침표와 언더바가 동시에 들어가면 안된다. -> 생성은 가능
- 이름에서 . -> - 또는 - -> . 로는 변경 불가능하다. ki_bong -> ki.bong 불가능

<span style="color:#f1c40f">작명을 할 때 카멜케이스 보다는 케밥케이스 또는 스네이크 표기법이 더 좋다 -> 휴먼 에러</span>

## 레코드

레코드는 타임스탬프, 메세지키, 메세지 값, 오프셋, 헤더로 구성되어 있다.

프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋과 타임스탬프가 지정되어 저장된다.
적재된 레코드는 수정 불가능이고 로그 리텐션 기간 또는 용량에 따라서만 삭제된다.


### 타임스탬프

프로듀서에서 해당 레코드가 생성된 시점에 설정(유닉스타임)
레코드의 타임스탬프로 언제 생성되었는지 알 수 있다.
다만, 임의로 설정할 수 있음을 유의해야한다.

### 메세지 키

메세지 값을 순서대로 처리하거나 메시지 값의 종류를 나타내기 위해 사용
메세지 키 사용 시 프로듀서 -> 토픽으로 전송 할 때 메시지 키의 해시값을 토대로 파티션을 지정
동일한 메시지 키라면 동일한 파티션에 들어가는 것이다.
어느 파티션인지는 알 수 없고 파티션 개수가 변경되면 메시지 키와 파티션 매칭이 달라지게 되므로 주의해야 한다.

메세지 키를 선언하지 않으면 null로 설정 된다.
이 레코드는 기본 설정 파티셔너에 따라 파티션에 분배되어 기재된다. 

### 메세지 값

실질적인 처리할 데이터
메시지 키와 값은 직렬화되어 브로커로 전송되기 때문에 컨슈머가 이용할 때는 직렬화한 형태와 동일한 형태로 역질렬화를 수행해야한다.

String -> String , Integer -> Integer

### 오프셋
컨슈머가 데이터를 가져갈 때 사용

레코드의 오프셋은 0 이상의 숫자로 이루어져 있고 레코드의 오프셋은 직접 지정 불가
이전의 전송된 레코드의 오프셋 + 1 값으로 생성된다.
컨슈머 그룹의 컨슈머가 파티션 데이터를 어디까지 가져갔는지 오프셋을 통해 어디까지 가져갔는지 명확이 알 수 있다.






여기서 메시지 브로커란
특정한 리소스에서 다른 쪽에 있는 리소스 또는 서비스 시스템으로 메시지를 전달할 때 사용되는 서버

즉 메세지를 전달시켜주는 역활을 하는 것이 메세지 서버, 메시지 브로커라고 보면 된다.

Producer/Consumer 분리 할 수 있다.

3개 이상의 브로커를 가지고 있는 클러스터링 구조 구성
브로커의 문제가 생겼을 경우 다른 브로커를 사용할 수 있어서 안전하게 메시지를 계속해서 사용할 수 있게 된다.

그리고 서버의 상태나, 서버의 리더, 문제에 대한 장애를 관리해주기 위한 코디네이터 시스템인 주키퍼를 같이 연동해서 사용하는 것이 일반적이다.

일반적인 사용방법
카프카 클라이언트

카프카에는 세가지가 존재한다.
Producer, Kafka Broker, Consumer

Producer : Broker에 데이터를 보내는 역활
Consumer  : Broker에 적재 되어 있는 데이터를 가져오는 역활

데이터가 전달되고 적재 되는 과정에서 정상적으로 수행이 되고 있는지를 알기 위해
Producer는 Acknowledgement Consumer는 Offset commit으로 확인 하게된다.

데이터를 담는 Topic, Partition, Offset으로 잘 처리 되었는지 확인한다.

네트워크 장애로 Acknowledgement 장애가 있는 경우 다시 보내게 된다.
이과정에서 중복된 데이터가 적재될 수 있으므로 카프카는  중복된 적재를 막기 위해멱등성 프로듀서를 사용하게 된다.

멱등성 프로듀서(Idempotence Producer)
카프카 3.0부터는 기본적으로 true로 사용하게 된다.
멱등성 프로듀서는 기본적인 프로듀서와 다르게 레코드를 브로커로 전송할 때 PID(Producer unique Id)와 SEQ(Sequence Number)를 전송하게 된다.

브로커는 PID와 SEQ를 가지고 있다가 중복 적재 요청이 오면 이후에 요청된 중복 레코드는 적재하지 않는다.

비동기 프로듀서로 작업해야 제대로 이 멱등성 프로듀서를 사용할 수 있다.
Producer가 Broker에 데이터를 보낼 때 PID와 SEQ가 함께 가게 되는데 이를 통해 중복을 피하게 된다.

Topic to Topic
변경이 되지 않고 계속 추가되는 데이터
지속적으로 



카프카 메세지를 신뢰성 있게 전달 하려면
3가지를 지켜야한다.

정확히 한번 - 중복성 금지
적어도 한번, 
최대 한번 - 데이터 유실